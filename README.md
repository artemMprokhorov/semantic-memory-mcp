<p align="center">
  <img src="logo.svg" width="200" alt="Semantic Memory MCP Logo">
</p>

# Semantic Memory MCP

**Personal Knowledge Management with Semantic Search for AI Assistants**

A self-hosted MCP (Model Context Protocol) server that adds persistent, semantically-searchable memory to Claude and other AI assistants. Store notes, thoughts, and knowledge â€” search them by meaning, not just keywords.

![License](https://img.shields.io/badge/license-dual-blue.svg)
![Python](https://img.shields.io/badge/python-3.9+-green.svg)
![Docker](https://img.shields.io/badge/docker-ready-blue.svg)

## âœ¨ Features

- **Semantic Search** â€” Find notes by meaning using 384-dimensional embeddings (all-MiniLM-L6-v2)
- **MCP Integration** â€” Works directly with Claude.ai via Remote MCP Servers
- **Self-Hosted** â€” Your data stays on your hardware
- **Docker Ready** â€” One command deployment
- **Embedding Consistency** â€” Automatic drift detection protects search quality
- **Auto-Backup** â€” Scheduled backups with easy restore

## ğŸ¯ Use Cases

- **Personal Knowledge Base** â€” Store and retrieve information semantically
- **Research Notes** â€” Organize findings, search by concepts
- **Learning Journal** â€” Track what you learn, find connections
- **Project Context** â€” Give your AI assistant memory of your projects

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- ngrok account (for remote access)
- Python 3.9+ (for local development)

### 1. Clone & Configure

```bash
git clone https://github.com/artemMprokhorov/semantic-memory-mcp.git
cd semantic-memory-mcp
cp .env.example .env
# Edit .env with your settings
```

### 2. Start the Server

```bash
docker-compose up -d
```

### 3. Setup ngrok Tunnel

```bash
ngrok http 5000
```

### 4. Connect to Claude.ai

1. Go to Claude.ai â†’ Settings â†’ Integrations
2. Add Remote MCP Server
3. Enter your ngrok URL: `https://your-subdomain.ngrok-free.app/sse`
4. Add your API key as URL parameter: `?api_key=YOUR_KEY`

## ğŸ“‹ System Requirements

### Minimum
- **RAM:** 4GB (embedding model needs ~2GB)
- **Disk:** 2GB free space (for Docker image + model cache)
- **CPU:** Any modern x64/ARM64 processor
- **OS:** Linux, macOS, Windows (with Docker)

### Recommended
- **RAM:** 8GB+
- **Disk:** 5GB+ (for larger databases)
- **SSD:** Recommended for faster embedding operations

### Software
- Docker & Docker Compose v2.0+
- ngrok account (free tier works)
- Python 3.9+ (only for local development)

### Tested On
- macOS (Apple Silicon M3 Ultra)

### Should Work On (untested)
- Linux distributions with Docker support
- Windows 11 + WSL2 + Docker Desktop
- Other macOS versions (Intel/ARM)

## ğŸ“– Documentation

- [Architecture Overview](docs/ARCHITECTURE.md)
- [Setup Guide](docs/SETUP_GUIDE.md)
- [MCP Integration](docs/MCP_INTEGRATION.md)
- [API Reference](docs/API_REFERENCE.md)
- [Troubleshooting](docs/TROUBLESHOOTING.md)

## ğŸ› ï¸ Available Tools

Once connected, Claude has access to these tools:

| Tool | Description |
|------|-------------|
| `search_neural_memory` | Semantic search through your notes |
| `add_note` | Save a new note with auto-embedding |
| `update_note` | Modify existing note |
| `delete_note` | Remove a note |
| `neural_stats` | View memory statistics |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Claude.ai  â”‚â”€â”€â”€â”€â–¶â”‚   ngrok     â”‚â”€â”€â”€â”€â–¶â”‚  MCP Server     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  (Flask + SSE)  â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                            â–¼                            â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚  â”‚  Embedding  â”‚    â”‚   SQLite    â”‚    â”‚ Consistency â”‚ â”‚
                    â”‚  â”‚   Model     â”‚    â”‚  Database   â”‚    â”‚    Check    â”‚ â”‚
                    â”‚  â”‚ (MiniLM-L6) â”‚    â”‚             â”‚    â”‚             â”‚ â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â”‚                        Docker Container                 â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”’ Security

- API key authentication (URL parameter or header)
- Self-hosted â€” data never leaves your server
- Optional: SSL/TLS with your own certificates

## ğŸ§ª Embedding Consistency

One unique feature: **automatic embedding drift detection**.

When you rebuild the Docker image or update dependencies, the embedding model might produce slightly different vectors. This breaks semantic search silently â€” queries return wrong results.

Our solution:
1. On first start, calibration embeddings are saved
2. On every restart, current embeddings are compared to calibration
3. If drift detected â†’ warning + instructions to recompute

See [Troubleshooting](docs/TROUBLESHOOTING.md) for details.

## ğŸ“¦ Project Structure

```
semantic-memory-mcp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ mcp_sse_handler.py      # MCP protocol + tools
â”‚   â”œâ”€â”€ stable_embeddings.py    # Embedding model wrapper
â”‚   â”œâ”€â”€ embedding_check.py      # Consistency verification
â”‚   â””â”€â”€ neural_memory_server.py # Main Flask app
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ backup.sh               # Backup script
â”‚   â”œâ”€â”€ restore.sh              # Restore script
â”‚   â””â”€â”€ recompute_embeddings.py # Fix drift
â”œâ”€â”€ docs/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env.example
```

## ğŸ¤ Contributing

Contributions welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) first.

## ğŸ“„ Licensing

This project is dual-licensed:

- Open-source / personal / non-commercial use: MIT License  
  See the [LICENSE](LICENSE) file for full terms.
- Commercial use, SaaS integration, proprietary redistribution, closed-source derivative works, or any use that does not comply with MIT terms: requires a separate commercial license.  
  Contact: [system.uid@gmail.com] for pricing, terms, and licensing agreement.

## ğŸ™ Acknowledgments

- [Anthropic](https://anthropic.com) â€” for Claude and the MCP protocol
- [Sentence Transformers](https://www.sbert.net/) â€” for embedding models
- [ngrok](https://ngrok.com) â€” for tunneling

---

## ğŸ‘¥ Authors

**Artem Prokhorov** â€” Creator and primary author

**Development approach:** This system emerged through intensive human-AI collaboration. Major architectural contributionsâ€”including semantic search, embedding consistency checks, and technical documentationâ€”were developed iteratively with Claude (Anthropic).

Built with ğŸ§  by Artem Prokhorov
